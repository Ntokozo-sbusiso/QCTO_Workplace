{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QCTO - Workplace Module\n",
    "\n",
    "### Project Title: Vegetable Prices Data Analysis\n",
    "#### Done By: Ntokozo Hadebe\n",
    "\n",
    "Â© ExploreAI 2024\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "<a href=#BC> Background Context</a>\n",
    "\n",
    "<a href=#one>1. Importing Packages</a>\n",
    "\n",
    "<a href=#two>2. Data Collection and Description</a>\n",
    "\n",
    "<a href=#three>3. Loading Data </a>\n",
    "\n",
    "<a href=#four>4. Data Cleaning and Filtering</a>\n",
    "\n",
    "<a href=#five>5. Exploratory Data Analysis (EDA)</a>\n",
    "\n",
    "<a href=#six>6. Modeling </a>\n",
    "\n",
    "<a href=#seven>7. Evaluation and Validation</a>\n",
    "\n",
    "<a href=#eight>8. Final Model</a>\n",
    "\n",
    "<a href=#nine>9. Conclusion and Future Work</a>\n",
    "\n",
    "<a href=#ten>10. References</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    " <a id=\"BC\"></a>\n",
    "## **Background Context**\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "* **Purpose:** Introduce the project, outline its goals, and explain its significance.\n",
    "\n",
    "The agricultural sector in India is vital to its economy, with vegetables holding particular significance due to their essential role in diets and economic livelihoods.\n",
    "\n",
    "Understanding the fluctuations in vegetable prices is crucial for farmers, consumers, and policymakers alike, as these prices directly impact income, household budgets, and food security. Fluctuations in vegetable prices can also have broader implications on inflation rates and macroeconomic stability.\n",
    "\n",
    "Through this project, we aim to explore the patterns behind vegetable price fluctuations, providing insights that can inform policies aimed at promoting agricultural sustainability, ensuring food affordability, and enhancing economic welfare across India\n",
    "\n",
    "* **Details:** Include information about the problem domain, the specific questions or challenges the project aims to address, and any relevant background information that sets the stage for the work.\n",
    "\n",
    "#### The analysis aims to address several key research questions pertaining to vegetable price dynamics:\n",
    "\n",
    "- Identify patterns of seasonal variation in vegetable prices.\n",
    "- Examine how seasonal trends affect pricing trends for different vegetable types.\n",
    "- Identify trends and patterns in vegetable prices over time through exploratory data analysis.\n",
    "- Explore seasonal variations in vegetable prices to understand their cyclical nature.\n",
    "- Provide actionable insights for stakeholders in the agricultural industry to support decision-making processes, enhance market efficiency, and improve economic outcomes.\n",
    "\n",
    "By addressing these research questions, the study aims to provide valuable insights into the determinants of vegetable prices and potential strategies to improve price stability in agricultural markets.\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a href=#one></a>\n",
    "## **Importing Packages**\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "* **Purpose:** Set up the Python environment with necessary libraries and tools.\n",
    "* **Details:** List and import all the Python packages that will be used throughout the project such as Pandas for data manipulation, Matplotlib/Seaborn for visualization, scikit-learn for modeling, etc.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please use code cells to code in and do not forget to comment your code.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a href=#two></a>\n",
    "## **Data Collection and Description**\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "* **Purpose:** Describe how the data was collected and provide an overview of its characteristics.\n",
    "* **Details:** Mention sources of the data, the methods used for collection (e.g., APIs, web scraping, datasets from repositories), and a general description of the dataset including size, scope, and types of data available (e.g., numerical, categorical).\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset overview\n",
    "- The dataset used for this analysis was sourced from Kaggle on May 7, 2024. It originated from an authorized source, the Agricultural Marketing Information Network (AGMARKNET), available at https://agmarknet.gov.in/.\n",
    "\n",
    "- It offers a comprehensive overview of vegetable prices across various regio and regions in Indians, making it a valuable resource for researchers, analysts, and enthusiasts interested in studying pricing dynamics. The dataset contains information on a diverse array of vegetables, providing detailed price records over time.\n",
    "\n",
    "- Attributes included in the dataset comprise vegetable types, price data, and time periods covered, allowing for a thorough exploration of pricing trends and patterns. Prior to analysis, data cleaning and preprocessing steps were undertaken to ensure data quality and integrity. These steps can be observed in the Data Cleaning section below.\n",
    "\n",
    "#### Datatypes:\n",
    "\n",
    "- Price Dates is of 'object' datatype.\n",
    "- The vegetable price datatypes is in numerical type.\n",
    "- There are inconsistencies in the vegetable price datatypes, with some vegetables being of 'integer' datatype, whilst - - others are of 'float' datatype.\n",
    "\n",
    "\n",
    "- The dataset consists of 287 observations (rows) and 11 features (columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a href=#three></a>\n",
    "## **Loading Data**\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "* **Purpose:** Load the data into the notebook for manipulation and analysis.\n",
    "* **Details:** Show the code used to load the data and display the first few rows to give a sense of what the raw data looks like.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data used for this project is located in the prices.csv file. This file is loaded into a Pandas DataFrame (called df) using the pd.read_csv() function. This function reads the CSV file and converts it into a DataFrame for further manipulation and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price Dates</th>\n",
       "      <th>Bhindi (Ladies finger)</th>\n",
       "      <th>Tomato</th>\n",
       "      <th>Onion</th>\n",
       "      <th>Potato</th>\n",
       "      <th>Brinjal</th>\n",
       "      <th>Garlic</th>\n",
       "      <th>Peas</th>\n",
       "      <th>Methi</th>\n",
       "      <th>Green Chilli</th>\n",
       "      <th>Elephant Yam (Suran)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-01-2023</td>\n",
       "      <td>35.0</td>\n",
       "      <td>18</td>\n",
       "      <td>22.0</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>45.0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02-01-2023</td>\n",
       "      <td>35.0</td>\n",
       "      <td>16</td>\n",
       "      <td>22.0</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>55</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>40.0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03-01-2023</td>\n",
       "      <td>35.0</td>\n",
       "      <td>16</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>55</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>40.0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04-01-2023</td>\n",
       "      <td>30.0</td>\n",
       "      <td>16</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22</td>\n",
       "      <td>25</td>\n",
       "      <td>55</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>40.0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08-01-2023</td>\n",
       "      <td>35.0</td>\n",
       "      <td>16</td>\n",
       "      <td>20.0</td>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "      <td>55</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>35.0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Price Dates  Bhindi (Ladies finger)  Tomato  Onion  Potato  Brinjal  Garlic  \\\n",
       "0  01-01-2023                    35.0      18   22.0      20       30      50   \n",
       "1  02-01-2023                    35.0      16   22.0      20       30      55   \n",
       "2  03-01-2023                    35.0      16   21.0      20       30      55   \n",
       "3  04-01-2023                    30.0      16   21.0      22       25      55   \n",
       "4  08-01-2023                    35.0      16   20.0      21       25      55   \n",
       "\n",
       "   Peas  Methi  Green Chilli  Elephant Yam (Suran)  \n",
       "0    25      8          45.0                    25  \n",
       "1    25      7          40.0                    25  \n",
       "2    25      7          40.0                    25  \n",
       "3    25      7          40.0                    25  \n",
       "4    22      6          35.0                    25  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the dataset\n",
    "df = pd.read_csv('prices.csv')\n",
    "\n",
    "# making the copy of dataset \n",
    "df_copy = df.copy()\n",
    "\n",
    "# displaying the firt few rows of the Dataframe\n",
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a href=#four></a>\n",
    "## **Data Cleaning and Filtering**\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "* **Purpose:** Prepare the data for analysis by cleaning and filtering.\n",
    "* **Details:** Include steps for handling missing values, removing outliers, correcting errors, and possibly reducing the data (filtering based on certain criteria or features).\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renaming Columns\n",
    "\n",
    "- The rename_columns function serves to standardize column names in a DataFrame according to PEP 8 principles, ensuring consistency and readability within the dataset and simplifying downstream data analysis and visualisation tasks. The function defines a dictionary called 'renamed_columns' that maps each column by name to its standardised name - with all lowercase and spaces replaced by underscores. It then renames each column in the DataFrame by making use of the .rename() method in combination with the 'rename_columns' dictionary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(df):\n",
    "    \"\"\"\n",
    "    Rename columns of a DataFrame according to PEP 8 principles, by converting column names to lowercase and replacing spaces or\n",
    "        special characters with underscores..\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): Input DataFrame with columns to be renamed.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame with columns renamed according to PEP 8.\n",
    "    \"\"\"\n",
    "    # dictionary mapping column names to standardised names\n",
    "    renamed_columns = {\n",
    "        'Price Dates': 'price_dates',\n",
    "        'Bhindi (Ladies finger)': 'bhindi',\n",
    "        'Tomato': 'tomato',\n",
    "        'Onion': 'onion',\n",
    "        'Potato': 'potato',\n",
    "        'Brinjal': 'brinjal',\n",
    "        'Garlic': 'garlic',\n",
    "        'Peas': 'peas',\n",
    "        'Methi': 'methi',\n",
    "        'Green Chilli': 'green_chilli',\n",
    "        'Elephant Yam (Suran)': 'elephant_yam'\n",
    "    }\n",
    "    return df.rename(columns=renamed_columns)\n",
    "\n",
    "# Rename columns\n",
    "df_copy = rename_columns(df_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting Data Types\n",
    "\n",
    "- The convert_data_types function transforms the data types of specific columns in the DataFrame for consistency and accuracy:\n",
    "\n",
    "1. It converts integer columns (representing vegetable prices) to floats using .astype(float) to ensure compatibility and facilitate numerical operations.\n",
    "2. It converts the 'price_dates' column to datetime using .to_datetime() with format='%d-%m-%Y' for accurate time-based analysis.\n",
    "\n",
    "This improves data integrity and reduces errors in further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data_types(df):\n",
    "    \"\"\"\n",
    "    Convert data types of columns within a DataFrame.\n",
    "\n",
    "    This function converts integer columns to float. \n",
    "    Additionally, it standardizes the format of the 'price_dates' column to datetime objects with the format \"%d-%m-%Y\".\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): Input DataFrame with columns to be converted.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame with data types converted as specified.\n",
    "    \"\"\"\n",
    "    # Convert integer columns to float\n",
    "    int_columns = df.select_dtypes(include='int64').columns\n",
    "    df[int_columns] = df[int_columns].astype(float)\n",
    "    \n",
    "    # Convert 'price_dates' column to datetime with correct format\n",
    "    df['price_dates'] = pd.to_datetime(df['price_dates'], format='%d-%m-%Y')\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Convert data types\n",
    "df_copy = convert_data_types(df_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for Missing Values\n",
    "\n",
    "The check_missing_values function serves as a utility to quickly identify and report any null values present in each column of a DataFrame. By iterating through each column and using the .isnull() and .sum() methods, it calculates the count of null values in each column. The function then prints out the count of null values alongside the corresponding column name, providing a clear overview of the null value distribution within the DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values count for each column: \n",
      "---------------------------------------------\n",
      "price_dates: 0\n",
      "bhindi: 0\n",
      "tomato: 0\n",
      "onion: 0\n",
      "potato: 0\n",
      "brinjal: 0\n",
      "garlic: 0\n",
      "peas: 0\n",
      "methi: 0\n",
      "green_chilli: 0\n",
      "elephant_yam: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Handle missing values\n",
    "def check_missing_values(df):\n",
    "    \"\"\"check for null values in each column of a Dataframe and print the count of null values, \n",
    "    along with column-specific null parameters\n",
    "    \"\"\"\n",
    "    print(f'Null values count for each column: ')\n",
    "    print('---------------------------------------------')\n",
    "\n",
    "    for col in df.columns:\n",
    "        null_count = df_copy[col].isnull().sum()\n",
    "        print(f'{col}: {null_count}')\n",
    "\n",
    "check_missing_values(df_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:\n",
    "\n",
    " This result confirms that there are no missing values identified in the DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for Duplicate Rows\n",
    "\n",
    "- The count_dupl_rows function identifies and counts duplicate rows in the dataset using .duplicated().sum(). It helps ensure data quality by detecting and guiding the removal of redundant rows, improving the accuracy of analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows 0\n"
     ]
    }
   ],
   "source": [
    "# Count the number of duplicate rows in a pandas DataFrame.\n",
    "def count_dupl_rows(df):\n",
    "    duplicates = df.duplicated().sum()\n",
    "    return duplicates\n",
    "\n",
    "print(f'Number of duplicate rows {count_dupl_rows(df_copy)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for Duplicate Date\n",
    "\n",
    "- We also need to check for duplicate dates in the 'price_dates' column to make sure thereâs only one price for each date.\n",
    "- The count_duplicate_dates function will count how many duplicate dates exist in this column, helping to ensure accurate time-based analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of duplicate dates: 0\n"
     ]
    }
   ],
   "source": [
    "def count_duplicate_dates(df):\n",
    "    duplicates = df.duplicated(subset=['price_dates']).sum()\n",
    "    return duplicates\n",
    "print(f'The number of duplicate dates: {count_duplicate_dates(df_copy)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identifying Potential Outliers\n",
    "\n",
    "- The check_outliers function identifies outliers in vegetable prices using descriptive statistics. It calculates the mean, median, standard deviation, and interquartile range (IQR) for each float column in the DataFrame. Values outside the IQR range are flagged as potential outliers. The function returns a DataFrame showing the outliers, their count, and relevant statistics like mean and standard deviation for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Count of Outliers</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Standard Deviation</th>\n",
       "      <th>Potential Outliers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bhindi</td>\n",
       "      <td>7</td>\n",
       "      <td>29.444251</td>\n",
       "      <td>8.124815</td>\n",
       "      <td>[60.0, 50.0, 50.0, 50.0, 50.0, 50.0, 55.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tomato</td>\n",
       "      <td>1</td>\n",
       "      <td>16.006969</td>\n",
       "      <td>0.118056</td>\n",
       "      <td>[18.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>onion</td>\n",
       "      <td>24</td>\n",
       "      <td>20.649826</td>\n",
       "      <td>11.711204</td>\n",
       "      <td>[45.0, 57.0, 55.0, 54.0, 54.0, 50.0, 50.0, 47.0, 50.0, 50.0, 47.0, 45.0, 46.0, 46.0, 45.0, 45.0, 46.0, 50.0, 47.0, 46.0, 47.0, 48.0, 46.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>potato</td>\n",
       "      <td>0</td>\n",
       "      <td>18.585366</td>\n",
       "      <td>2.726238</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brinjal</td>\n",
       "      <td>13</td>\n",
       "      <td>31.655052</td>\n",
       "      <td>11.725421</td>\n",
       "      <td>[60.0, 70.0, 70.0, 60.0, 60.0, 70.0, 60.0, 70.0, 80.0, 70.0, 70.0, 80.0, 60.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>garlic</td>\n",
       "      <td>1</td>\n",
       "      <td>133.101045</td>\n",
       "      <td>60.078331</td>\n",
       "      <td>[290.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>peas</td>\n",
       "      <td>5</td>\n",
       "      <td>66.658537</td>\n",
       "      <td>33.302415</td>\n",
       "      <td>[150.0, 150.0, 150.0, 150.0, 150.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>methi</td>\n",
       "      <td>10</td>\n",
       "      <td>20.383275</td>\n",
       "      <td>117.428417</td>\n",
       "      <td>[2000.0, 30.0, 30.0, 35.0, 35.0, 30.0, 30.0, 30.0, 30.0, 30.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>green_chilli</td>\n",
       "      <td>12</td>\n",
       "      <td>44.122404</td>\n",
       "      <td>12.796590</td>\n",
       "      <td>[0.13, 80.0, 90.0, 80.0, 90.0, 80.0, 80.0, 75.0, 90.0, 80.0, 80.0, 80.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>elephant_yam</td>\n",
       "      <td>50</td>\n",
       "      <td>28.797909</td>\n",
       "      <td>6.607973</td>\n",
       "      <td>[15.0, 15.0, 15.0, 40.0, 12.0, 40.0, 40.0, 40.0, 40.0, 15.0, 15.0, 15.0, 50.0, 15.0, 15.0, 12.0, 12.0, 40.0, 40.0, 50.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 45.0, 40.0, 40.0, 40.0, 40.0, 40.0, 50.0, 40.0, 50.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Column  Count of Outliers        Mean  Standard Deviation  \\\n",
       "0        bhindi                  7   29.444251            8.124815   \n",
       "1        tomato                  1   16.006969            0.118056   \n",
       "2         onion                 24   20.649826           11.711204   \n",
       "3        potato                  0   18.585366            2.726238   \n",
       "4       brinjal                 13   31.655052           11.725421   \n",
       "5        garlic                  1  133.101045           60.078331   \n",
       "6          peas                  5   66.658537           33.302415   \n",
       "7         methi                 10   20.383275          117.428417   \n",
       "8  green_chilli                 12   44.122404           12.796590   \n",
       "9  elephant_yam                 50   28.797909            6.607973   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                             Potential Outliers  \n",
       "0                                                                                                                                                                                                                                                                    [60.0, 50.0, 50.0, 50.0, 50.0, 50.0, 55.0]  \n",
       "1                                                                                                                                                                                                                                                                                                        [18.0]  \n",
       "2                                                                                                                                                              [45.0, 57.0, 55.0, 54.0, 54.0, 50.0, 50.0, 47.0, 50.0, 50.0, 47.0, 45.0, 46.0, 46.0, 45.0, 45.0, 46.0, 50.0, 47.0, 46.0, 47.0, 48.0, 46.0, 48.0]  \n",
       "3                                                                                                                                                                                                                                                                                                            []  \n",
       "4                                                                                                                                                                                                                                [60.0, 70.0, 70.0, 60.0, 60.0, 70.0, 60.0, 70.0, 80.0, 70.0, 70.0, 80.0, 60.0]  \n",
       "5                                                                                                                                                                                                                                                                                                       [290.0]  \n",
       "6                                                                                                                                                                                                                                                                           [150.0, 150.0, 150.0, 150.0, 150.0]  \n",
       "7                                                                                                                                                                                                                                                [2000.0, 30.0, 30.0, 35.0, 35.0, 30.0, 30.0, 30.0, 30.0, 30.0]  \n",
       "8                                                                                                                                                                                                                                      [0.13, 80.0, 90.0, 80.0, 90.0, 80.0, 80.0, 75.0, 90.0, 80.0, 80.0, 80.0]  \n",
       "9  [15.0, 15.0, 15.0, 40.0, 12.0, 40.0, 40.0, 40.0, 40.0, 15.0, 15.0, 15.0, 50.0, 15.0, 15.0, 12.0, 12.0, 40.0, 40.0, 50.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 45.0, 40.0, 40.0, 40.0, 40.0, 40.0, 50.0, 40.0, 50.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify potential outliers in float columns of a DataFrame using descriptive statistics\n",
    "def check_outliers(df):\n",
    "    \n",
    "    outliers = []\n",
    "    for col in df.select_dtypes(include='float64').columns:\n",
    "    # Calculate descriptive statistics for the current column\n",
    "        desc_stats = df[col].describe()\n",
    "        mean = desc_stats['mean']  # Mean value of the column\n",
    "        std_dev = desc_stats['std']  # Standard deviation of the column\n",
    "        q1 = desc_stats['25%']  # First quartile (25th percentile) of the column\n",
    "        q3 = desc_stats['75%']  # Third quartile (75th percentile) of the column\n",
    "        iqr = q3 - q1  # Interquartile range (IQR) of the column\n",
    "        lower_bound = q1 - 1.5 * iqr  # Lower bound for potential outliers\n",
    "        upper_bound = q3 + 1.5 * iqr  # Upper bound for potential outliers\n",
    "\n",
    "        # Identify potential outliers in the current column\n",
    "        potential_outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)][col].tolist()\n",
    "\n",
    "        # Calculate the count of outliers\n",
    "        outlier_count = len(potential_outliers)\n",
    "\n",
    "        # Create a DataFrame to store the results\n",
    "        results = pd.DataFrame({\n",
    "            'Column': [col],\n",
    "            'Count of Outliers': [outlier_count],\n",
    "            'Mean': [mean],\n",
    "            'Standard Deviation': [std_dev],\n",
    "            'Potential Outliers': [potential_outliers]\n",
    "        })\n",
    "        \n",
    "        # Append the results DataFrame to the list\n",
    "        outliers.append(results)\n",
    "\n",
    "    # Concatenate the results DataFrames into a single DataFrame\n",
    "    outliers_df = pd.concat(outliers, ignore_index=True)\n",
    "    return outliers_df\n",
    "\n",
    "# Set the display options to show the entire content of the 'Potential Outliers' column\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Identify potential outliers\n",
    "outliers = check_outliers(df_copy)\n",
    "outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results:\n",
    "\n",
    "Most potential outliers are clustered around values above or below the mean, suggesting seasonality as a factor. To explore this, we'll extract the month from the 'price_date' column and group vegetable prices by month. A time series plot will visualize this trend in the Exploratory Data Analysis.\n",
    "\n",
    "However, two extreme outliers likely indicate errors:\n",
    "\n",
    "- 'Methi' has an outlier at 2000.0, much higher than the mean.\n",
    "- 'Green Chilli' has an outlier at 0.13, much lower than the mean.\n",
    "\n",
    "These extreme outliers will be replaced by the mean of the 15 preceding and 15 following observations to account for seasonality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replacing Erroneous Outliers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_erroneous_outliers(df, column, outlier_values):\n",
    "    \"\"\"\n",
    "    Replace outliers in a DataFrame column with the mean of the 30 surrounding observations.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pandas.DataFrame): The DataFrame containing the outliers.\n",
    "    - column (str): The name of the column with outliers.\n",
    "    - outlier_values (list): List of outlier values to replace.\n",
    "\n",
    "    Returns:\n",
    "    - pandas.DataFrame: The DataFrame with outliers replaced.\n",
    "    \n",
    "    Note: Assumes the DataFrame is sorted chronologically.\n",
    "    \"\"\"\n",
    "    for outlier in outlier_values:\n",
    "        outlier_index = df.index[df[column] == outlier].tolist()[0]\n",
    "        lower_bound = max(outlier_index - 15, 0)\n",
    "        upper_bound = min(outlier_index + 15, len(df) - 1)\n",
    "\n",
    "        # Calculate the mean of the 30 surrounding values\n",
    "        mean_surrounding = df.loc[lower_bound:upper_bound, column].mean()\n",
    "\n",
    "        # Replace the outlier\n",
    "        df.at[outlier_index, column] = mean_surrounding\n",
    "\n",
    "    return df\n",
    "\n",
    "# Replace the identified outliers:\n",
    "df_copy = replace_erroneous_outliers(df_copy, 'methi', [2000.0])\n",
    "df_copy = replace_erroneous_outliers(df_copy, 'green_chilli', [0.13])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting Month to Explore Possible Seasonality\n",
    "\n",
    "The extract_month function extracts the month from a datetime column in a DataFrame and stores it in a new column. This is useful for time-series analysis to identify seasonal trends. It uses dt.strftime('%m-%Y') to format the date and creates a new column, 'price_months', for easier grouping, visualization, and analysis based on monthly patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price_dates</th>\n",
       "      <th>bhindi</th>\n",
       "      <th>tomato</th>\n",
       "      <th>onion</th>\n",
       "      <th>potato</th>\n",
       "      <th>brinjal</th>\n",
       "      <th>garlic</th>\n",
       "      <th>peas</th>\n",
       "      <th>methi</th>\n",
       "      <th>green_chilli</th>\n",
       "      <th>elephant_yam</th>\n",
       "      <th>price_months</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>35.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>01-2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>35.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>01-2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>35.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>01-2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>30.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>01-2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-08</td>\n",
       "      <td>35.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>01-2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  price_dates  bhindi  tomato  onion  potato  brinjal  garlic  peas  methi  \\\n",
       "0  2023-01-01    35.0    18.0   22.0    20.0     30.0    50.0  25.0    8.0   \n",
       "1  2023-01-02    35.0    16.0   22.0    20.0     30.0    55.0  25.0    7.0   \n",
       "2  2023-01-03    35.0    16.0   21.0    20.0     30.0    55.0  25.0    7.0   \n",
       "3  2023-01-04    30.0    16.0   21.0    22.0     25.0    55.0  25.0    7.0   \n",
       "4  2023-01-08    35.0    16.0   20.0    21.0     25.0    55.0  22.0    6.0   \n",
       "\n",
       "   green_chilli  elephant_yam price_months  \n",
       "0          45.0          25.0      01-2023  \n",
       "1          40.0          25.0      01-2023  \n",
       "2          40.0          25.0      01-2023  \n",
       "3          40.0          25.0      01-2023  \n",
       "4          35.0          25.0      01-2023  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extract month from a datetime column and create a new column to store the month values.\n",
    "\n",
    "def extract_month(df, date_colummn):\n",
    "\n",
    "    df['price_months'] = df[date_colummn].dt.strftime('%m-%Y')\n",
    "        \n",
    "    return df\n",
    "\n",
    "    # Extract the month:\n",
    "df_copy = extract_month(df_copy, 'price_dates')\n",
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing \n",
    "\n",
    "#### Data Normalization/Standardization:\n",
    "\n",
    "- Normalizing or standardizing numeric columns to bring all features into the same scale, which can be especially useful for machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_columns(df, columns):\n",
    "    scaler = StandardScaler()\n",
    "    df[columns] = scaler.fit_transform(df[columns])\n",
    "    return df\n",
    "\n",
    "# Normalize numeric columns\n",
    "numeric_columns = ['bhindi', 'tomato', 'onion', 'potato', 'brinjal', 'garlic', 'peas', 'methi', 'green_chilli', 'elephant_yam']\n",
    "df_copy = normalize_columns(df_copy, numeric_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price_dates</th>\n",
       "      <th>bhindi</th>\n",
       "      <th>tomato</th>\n",
       "      <th>onion</th>\n",
       "      <th>potato</th>\n",
       "      <th>brinjal</th>\n",
       "      <th>garlic</th>\n",
       "      <th>peas</th>\n",
       "      <th>methi</th>\n",
       "      <th>green_chilli</th>\n",
       "      <th>elephant_yam</th>\n",
       "      <th>price_months</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>0.684995</td>\n",
       "      <td>16.911535</td>\n",
       "      <td>0.115490</td>\n",
       "      <td>0.519802</td>\n",
       "      <td>-0.141397</td>\n",
       "      <td>-1.385628</td>\n",
       "      <td>-1.253101</td>\n",
       "      <td>-0.772110</td>\n",
       "      <td>0.059296</td>\n",
       "      <td>-0.57575</td>\n",
       "      <td>01-2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>0.684995</td>\n",
       "      <td>-0.059131</td>\n",
       "      <td>0.115490</td>\n",
       "      <td>0.519802</td>\n",
       "      <td>-0.141397</td>\n",
       "      <td>-1.302258</td>\n",
       "      <td>-1.253101</td>\n",
       "      <td>-0.907725</td>\n",
       "      <td>-0.340374</td>\n",
       "      <td>-0.57575</td>\n",
       "      <td>01-2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>0.684995</td>\n",
       "      <td>-0.059131</td>\n",
       "      <td>0.029953</td>\n",
       "      <td>0.519802</td>\n",
       "      <td>-0.141397</td>\n",
       "      <td>-1.302258</td>\n",
       "      <td>-1.253101</td>\n",
       "      <td>-0.907725</td>\n",
       "      <td>-0.340374</td>\n",
       "      <td>-0.57575</td>\n",
       "      <td>01-2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>0.068521</td>\n",
       "      <td>-0.059131</td>\n",
       "      <td>0.029953</td>\n",
       "      <td>1.254696</td>\n",
       "      <td>-0.568566</td>\n",
       "      <td>-1.302258</td>\n",
       "      <td>-1.253101</td>\n",
       "      <td>-0.907725</td>\n",
       "      <td>-0.340374</td>\n",
       "      <td>-0.57575</td>\n",
       "      <td>01-2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-08</td>\n",
       "      <td>0.684995</td>\n",
       "      <td>-0.059131</td>\n",
       "      <td>-0.055584</td>\n",
       "      <td>0.887249</td>\n",
       "      <td>-0.568566</td>\n",
       "      <td>-1.302258</td>\n",
       "      <td>-1.343342</td>\n",
       "      <td>-1.043340</td>\n",
       "      <td>-0.740044</td>\n",
       "      <td>-0.57575</td>\n",
       "      <td>01-2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  price_dates    bhindi     tomato     onion    potato   brinjal    garlic  \\\n",
       "0  2023-01-01  0.684995  16.911535  0.115490  0.519802 -0.141397 -1.385628   \n",
       "1  2023-01-02  0.684995  -0.059131  0.115490  0.519802 -0.141397 -1.302258   \n",
       "2  2023-01-03  0.684995  -0.059131  0.029953  0.519802 -0.141397 -1.302258   \n",
       "3  2023-01-04  0.068521  -0.059131  0.029953  1.254696 -0.568566 -1.302258   \n",
       "4  2023-01-08  0.684995  -0.059131 -0.055584  0.887249 -0.568566 -1.302258   \n",
       "\n",
       "       peas     methi  green_chilli  elephant_yam price_months  \n",
       "0 -1.253101 -0.772110      0.059296      -0.57575      01-2023  \n",
       "1 -1.253101 -0.907725     -0.340374      -0.57575      01-2023  \n",
       "2 -1.253101 -0.907725     -0.340374      -0.57575      01-2023  \n",
       "3 -1.253101 -0.907725     -0.340374      -0.57575      01-2023  \n",
       "4 -1.343342 -1.043340     -0.740044      -0.57575      01-2023  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a href=#five></a>\n",
    "## **Exploratory Data Analysis (EDA)**\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "* **Purpose:** Explore and visualize the data to uncover patterns, trends, and relationships.\n",
    "* **Details:** Use statistics and visualizations to explore the data. This may include histograms, box plots, scatter plots, and correlation matrices. Discuss any significant findings.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please use code cells to code in and do not forget to comment your code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a href=#six></a>\n",
    "## **Modeling**\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "* **Purpose:** Develop and train predictive or statistical models.\n",
    "* **Details:** Describe the choice of models, feature selection and engineering processes, and show how the models are trained. Include code for setting up the models and explanations of the model parameters.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please use code cells to code in and do not forget to comment your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a href=#seven></a>\n",
    "## **Evaluation and Validation**\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "* **Purpose:** Evaluate and validate the effectiveness and accuracy of the models.\n",
    "* **Details:** Present metrics used to evaluate the models, such as accuracy, precision, recall, F1-score, etc. Discuss validation techniques employed, such as cross-validation or train/test split.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please use code cells to code in and do not forget to comment your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a href=#eight></a>\n",
    "## **Final Model**\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "* **Purpose:** Present the final model and its performance.\n",
    "* **Details:** Highlight the best-performing model and discuss its configuration, performance, and why it was chosen over others.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please use code cells to code in and do not forget to comment your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a href=#nine></a>\n",
    "## **Conclusion and Future Work**\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "* **Purpose:** Summarize the findings and discuss future directions.\n",
    "* **Details:** Conclude with a summary of the results, insights gained, limitations of the study, and suggestions for future projects or improvements in methodology or data collection.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please use code cells to code in and do not forget to comment your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a href=#ten></a>\n",
    "## **References**\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "* **Purpose:** Provide citations and sources of external content.\n",
    "* **Details:** List all the references and sources consulted during the project, including data sources, research papers, and documentation for tools and libraries used.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please use code cells to code in and do not forget to comment your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Sections to Consider\n",
    "\n",
    "* ### Appendix: \n",
    "For any additional code, detailed tables, or extended data visualizations that are supplementary to the main content.\n",
    "\n",
    "* ### Contributors: \n",
    "If this is a group project, list the contributors and their roles or contributions to the project.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SQL_packages",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
